---
title: 04. 처리율 제한 장치의 설계
sidebar_position: 4
---
## 1. 처리율 제한 장치의 설계
- 클라이언트 또는 서비스가 보내는 트래픽 처리율을 제어하기 위한 장치
  - 예를 들면 HTTP 요청 횟수
  - 임계치(threshold)를 넘어가면 모든 요청은 중단되는 방식
- 처리율 제한 장치는 왜 필요할까?
  - DoS 공격에 의한 자원 고갈 방지
  - 서버 비용 절감(사용성은 떨어짐), 특히 사용료를 지불하는 API라면 제한을 중요하게 고려해야 함
  - 봇과 같은 잘못된 이용 패턴으로 유발된 트래픽을 걸러낼 수 있다.

## 1단계: 문제 이해 및 설계 범위 확정
- 면접관과 소통을 통해 어떤 제한 장치를 구현해야 하는지 확인할 것
- 알고리즘마다 고유의 장단점이 있는데 요구사항을 파악해야 적절한 알고리즘을 사용할 수 있다.


## 2단계: 개략적 설계안 제시 및 동의 구하기
### 처리율 제한 장치를 어디에 둘 것인가?
- 처리율 제한 장치는 클라이언트, 서버에 둘 수 있을 것이다.
  - 클라이언트: 위변조가 쉬워 안정적인 처리율 제한을 걸기에는 한계가 있다.
  - 서버: API 서버 내부에 둘 수도 있고, 외부에 middleware(또는 API Gateway)로 구성할 수도 있다.
- 서버에 둘 때 고민해볼 것
  - 현재 사용하는 프로그래밍 언어 또는 프레임 워크가 서버측 구현까지 지원하기에 충분히 효율적인가?
  - 처리율 알고리즘은 무엇을 선택할 것인가?
  - 기존 설계에 API Gateway가 포함되어 있는가?

### 처리율 제한 알고리즘

#### (1) 토큰 버킷 알고리즘
- 제한된 용량이 있는 버킷에 지정된 시간마다 지정된 개수의 토큰이 공급된다.
- 공급된 토큰 중 용량을 초과하고 남은 것은 버려진다.
- 매 요청은 버킷에서 토큰을 얻고 실행된다.
- 지정해줘야 하는 값
  - 버킷 크기
  - 토큰 공급률
  - 버킷 개수
- 장점
  - 구현이 쉽다
  - 메모리 사용에 있어 효율적이다.
- 단점
  - 3개의 매개변수들의 최적화가 까다롭다.


#### (2) 누출 버킷 알고리즘
- 큐를 두고 요청을 담는다.
- 큐가 가득 차있다면 요청은 버려지고, 지정된 시간마다 큐에서 요청을 꺼내 처리한다.
- 지정해줘야 하는 값
  - 버킷 크기: 큐 사이즈와 같은 값
  - 처리율: 지정된 시간에 몇 개의 항목을 처리할 것인지
- 장점
  - 크기가 제한되어 있어 메모리 사용에 있어 효율적이다.
  - 고정된 처리율이 있어 안정적인 출력이 가능하다.
- 단점
  - 단시간에 트래픽이 몰릴 경우 큐에는 오래된 요청들만 쌓이게 될 수 있다.(최신 요청들은 버려짐)
  - 2개의 매개변수 최적화가 까다롭다

#### (3) 고정 윈도 카운터 알고리즘
- 타임 라인을 고정된 간격인 윈도(window)로 나누고 각 윈도는 고정된 카운터(허용된 처리 개수)를 가진다.
- 요청이 접수될 때마다 카운터는 1씩 증가하고 설정값을 초과하면 새 윈도가 열릴 때까지 요청이 버려진다.
- 장점
  - 메모리 효율이 좋다
  - 이해가 쉽다
  - 특정 트래픽 패턴을 처리하기에 적합하다.
- 단점
  - 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰리면 기대했던 처리 한도를 초과하는 양을 처리할 수 있다.


#### (4) 이동 윈도 로깅 알고리즘
- 요청 처리 시간을 로그로 쌓는다(예를 들면 redis에)
- 각 요청은 설정된 시간만큼 저장되었다 제거된다.
- 요청이 들어왔을 때 쌓여있는 로그 수로 처리 가능 여부를 판단한다.
- 장점
  - 고정 윈도 카운터 알고리즘과 달리 어느 시점에 처리율을 보더라도 설정한 값을 넘지 않는다.
- 단점
  - 다량의 메모리를 사용하게 된다.


#### (5) 이동 윈도 카운터 알고리즘
- 우선 (3)과 같이 고정된 윈도와 카운터를 가진다.
- 단, 현재 처리율을 계산할 때 이전 윈도와 현재 윈도의 비율을 고려하는데
- 예를 들어 위도 크기는 100초이고 현재 새로운 윈도의 30초 시점이라고 가정해보자
- 처리량 계산 공식은 다음과 같다 (이전 윈도 요청 수 * 0.7 + 현재 윈도 요청 수)
- 장점
  - (3)에 비해 짧은 시간에 몰리는 트래픽에도 잘 동작한다
  - 메모리 효율이 좋다.
- 단점
  - 요청이 균등하게 분포되어 있다고 가정했기 때문에 처리율 제한 장치가 다소 느슨하다.


## 3단계: 상세 설계
### 처리율 한도 초과 트래픽 처리 전략
- HTTP Header를 통해 현재 가능한 처리율 상태를 사용자에게 알릴 수 있다.
  - X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청의 수
  - X-Ratelimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
  - X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림
  - 사용자가 너무 많은 요청을 보내면 429 too many requests와 함께 X-Ratelimit-Retry-After를 보내자!

### 분산 환경에서의 처리율 제한 장치의 구현
- `경쟁 조건`
  - redis를 사용할 경우 다음과 같은 동작을 수행한다.
  - (1) redis에서 처리 값을 가져온다 (2) 처리 값 + 1이 임계치를 넘는지 확인한다. (3) 레디스에 보관된 카운터 값을 1만큼 증가시킨다.
  - 이는 경쟁 조건을 발생시킨다.
  - 락(Lock)을 사용할 수 있으나 성능을 상당히 떨어뜨린다...
  - 책에서는 루아 스크립트/redis 정렬 집합이라는 개념만 던져준다.
- `동기화 이슈`
  - 처리율 제한 장치가 늘어나면 동기화가 필요해진다.
  - redis와 같은 중앙 집중형 데이터 저장소를 사용하여 동기화 이슈를 해결할 수 있다.

### 성능 최적화
- 글로벌 서비스의 경우 여러대의 엣지 서버를 두고 사용자에게 가장 가까운 서버로 트래픽이 전달되도록 성능을 최적화할 것이다.
- 이렇게 여러대의 서버를 두면 동기화 문제를 다뤄야 하는데 이때 `최종 일관성 모델`을 사용하라고 권한다 (최종 일관성 모델은 6장에서..)

### 모니터링
- 처리율 제한 장치가 잘 동작하는지 모니터링을 통해 확인할 부분은 2가지이다.
  - 채택된 처리율 제한 알고리즘이 효과적인가?
  - 정의한 처리율 제한 규칙이 효과적인가?
- 이를 위해 아래 2가지 데이터를 확인할 수 있도록 준비가 필요하다.
  - 너무 많은 유효 요청이 버려지지는 않았는가?
  - 이벤트성으로 트래픽이 급증할 때도 요청을 잘 받아내는가?

## 4단계: 마무리, 처리율 제한 장치의 종류
- 경성 또는 연성
  - 경성: 임계치를 절대 넘을 수 없음
  - 연성: 임계치를 넘을 수 있음
- 계층별 처리율 제한 장치
- 처리율 제한을 회피하는 방법
  - 클라이언트 측 Cache 활용하여 API 호출 횟수를 줄인다.
  - 처리율 제한 임계치를 이해하고 이에 맞게 요청하도록 클라이언트를 개발한다.
  - 예외나 에러 처리 코드를 도입하여 제한에 걸려도 복구가 가능하도록 개발한다.
  - 충분한 백오프(back-off) 시간을 두고 재시도 로직을 구현한다.